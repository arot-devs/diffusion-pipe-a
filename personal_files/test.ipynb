{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20241222 创建repo的过程:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --recurse-submodules https://github.com/tdrussell/diffusion-pipe\n",
    "\n",
    "\n",
    "!conda create -n diffusion-pipe python=3.12\n",
    "!conda activate diffusion-pipe\n",
    "\n",
    "!pip install xformers \"torch<2.4\" torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -U \n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move model weights to local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aesthetic-shadow-v2\tcomplexity_ic9600_ck.pth  hydit_v1.2_kohya\n",
      "clip-vit-large-patch14\tconvnextv2-base-22k-384   style_emb\n"
     ]
    }
   ],
   "source": [
    "!ls  /rmd/yada/model_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aesthetic-shadow-v2\t  hunyuan_video_t2v_720p_bf16.safetensors\n",
      "clip-vit-large-patch14\t  hydit_v1.2_kohya\n",
      "complexity_ic9600_ck.pth  llava-llama-3-8b-text-encoder-tokenizer\n",
      "convnextv2-base-22k-384   style_emb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rmd/yada/model_weights\n",
      "aesthetic-shadow-v2\t  hunyuan_video_t2v_720p_bf16.safetensors\n",
      "clip-vit-large-patch14\t  hydit_v1.2_kohya\n",
      "complexity_ic9600_ck.pth  llava-llama-3-8b-text-encoder-tokenizer\n",
      "convnextv2-base-22k-384   style_emb\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /lv0/yada/tmp_dev\n",
    "%cd /rmd/yada/model_weights/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30G\tllava-llama-3-8b-text-encoder-tokenizer\n"
     ]
    }
   ],
   "source": [
    "!du -sh llava-llama-3-8b-text-encoder-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 minutes\n",
    "!cp -r clip-vit-large-patch14 llava-llama-3-8b-text-encoder-tokenizer  /lv0/yada/tmp_dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 minutes\n",
    "!cp hunyuanVideoSafetensors_vae.safetensors hunyuan_video_t2v_720p_bf16.safetensors /lv0/yada/tmp_dev/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running trainer (in diffusion-pipe repo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepspeed --num_gpus=1 train.py --deepspeed --config personal_files/test_hunyuan_video.toml --regenerate_cache\n",
    "\n",
    "deepspeed --num_gpus=1 train.py --deepspeed --config personal_files/test_hunyuan_video.toml\n",
    "\n",
    "deepspeed --num_gpus=1 train.py --deepspeed --config personal_files/test_hunyuan_video_pixel.toml --regenerate_cache\n",
    "\n",
    "deepspeed --num_gpus=8 train.py --deepspeed --config personal_files/test_hunyuan_video_illust.toml\n",
    "\n",
    "\n",
    "deepspeed --num_gpus=6 train.py --deepspeed --config personal_files/test_hunyuan_video_illust.toml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comfyui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n comfyui python=3.12\n",
    "\n",
    "# torch 2.5.1\n",
    "pip install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_flow / setup_comfy\n",
    "import os\n",
    "\n",
    "def find_requirements_dirs(base_dir):\n",
    "    # Find all direct subdirectories with a requirements.txt\n",
    "    dirs_with_requirements = [\n",
    "        os.path.join(base_dir, d)\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and os.path.exists(os.path.join(base_dir, d, 'requirements.txt'))\n",
    "    ]\n",
    "    return dirs_with_requirements\n",
    "\n",
    "def generate_install_command(requirements_dirs):\n",
    "    # Generate the install command for each directory\n",
    "    command = ' && '.join(\n",
    "        [f'pip install -r {os.path.join(d, \"requirements.txt\")}' for d in requirements_dirs]\n",
    "    )\n",
    "    return command\n",
    "\n",
    "base_directory = '/rmt/yada/apps/comfyui/custom_nodes'\n",
    "requirements_dirs = find_requirements_dirs(base_directory)\n",
    "\n",
    "if requirements_dirs:\n",
    "    install_command = generate_install_command(requirements_dirs)\n",
    "    print(install_command)\n",
    "else:\n",
    "    print(\"No subdirectories with requirements.txt found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
